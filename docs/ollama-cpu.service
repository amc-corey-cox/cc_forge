[Unit]
Description=Ollama Service (CPU Only)
After=network-online.target

[Service]
ExecStart=/usr/local/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3

# CPU only - disable all GPU backends
Environment="OLLAMA_NUM_GPU=0"
Environment="OLLAMA_HOST=127.0.0.1:11434"

# Keep models loaded indefinitely (avoid reload delays)
Environment="OLLAMA_KEEP_ALIVE=-1"

[Install]
WantedBy=default.target
